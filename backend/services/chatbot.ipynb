{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a939806f-ead7-4ea4-982a-fbfd3c1cb9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "735d96f6-a990-41ca-a375-d96fed880664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 🔐 Chargement des variables d'environnement\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# ✅ Chemin robuste pour compatibilité Jupyter + Streamlit\n",
    "try:\n",
    "    BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "except NameError:\n",
    "    BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "\n",
    "CSV_PATH = os.path.join(BASE_DIR, \"data\", \"donnees_nettoyees.csv\")\n",
    "\n",
    "def charger_donnees():\n",
    "    return pd.read_csv(CSV_PATH)\n",
    "\n",
    "def extraire_contexte(question: str, df: pd.DataFrame) -> str:\n",
    "    question_lower = question.lower()\n",
    "\n",
    "    # 🔍 Filtrage par flux\n",
    "    if \"export\" in question_lower:\n",
    "        df = df[df[\"Flux\"].str.contains(\"export\", case=False)]\n",
    "    elif \"import\" in question_lower:\n",
    "        df = df[df[\"Flux\"].str.contains(\"import\", case=False)]\n",
    "\n",
    "    # 🔍 Filtrage par année\n",
    "    for annee in df[\"Année\"].dropna().unique():\n",
    "        if str(int(annee)) in question_lower:\n",
    "            df = df[df[\"Année\"] == int(annee)]\n",
    "\n",
    "    # 🧮 Résumé des montants par produit\n",
    "    resume = (\n",
    "        df.groupby(\"Produit\")[\"Montant\"]\n",
    "        .sum()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(10)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # 📜 Formatage du contexte pour GPT\n",
    "    texte = \"Produit\\tMontant total (FCFA)\\n\"\n",
    "    texte += \"\\n\".join([f\"{row['Produit']}\\t{row['Montant']:.0f}\" for _, row in resume.iterrows()])\n",
    "    return texte\n",
    "\n",
    "def generer_reponse_llm(question: str, contexte: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Tu es un expert économique du Sénégal. Réponds à la question suivante\n",
    "    en te basant uniquement sur le CONTEXTE fourni :\n",
    "\n",
    "    CONTEXTE :\n",
    "    {contexte}\n",
    "\n",
    "    QUESTION :\n",
    "    {question}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Tu es un analyste économique du Sénégal.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"❌ Erreur lors de la génération : {e}\"\n",
    "\n",
    "def poser_question_llm(question: str) -> str:\n",
    "    df = charger_donnees()\n",
    "    contexte = extraire_contexte(question, df)\n",
    "    return generer_reponse_llm(question, contexte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e130554a-1bc9-465c-a320-669951273e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Test du chatbot économique du Sénégal\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "❓ Pose ta question (ou 'exit') :  quels sont les produits les plus importes en 2014,2015 et 2016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 Réponse :\n",
      "\n",
      "Les produits les plus importés au Sénégal en 2014, 2015 et 2016 sont les suivants, classés par ordre décroissant de montant total en FCFA :\n",
      "\n",
      "1. Combustibles minéraux; huiles, cires minérales; matières bitumineuses\n",
      "2. Réacteurs nucléaires; chaudières, machines, appareils, engins mécaniques\n",
      "3. Céréales\n",
      "4. Voitures automobiles et autres véhicules terrestres; parties, accessoires\n",
      "5. Machines électriques; appareils d'émission-réception radio/TV\n",
      "\n",
      "Ces produits représentent les importations les plus importantes pour ces années données.\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "❓ Pose ta question (ou 'exit') :  la moyenne des produits importes en 2014 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 Réponse :\n",
      "\n",
      "Pour calculer la moyenne des produits importés en 2014, il faut d'abord additionner tous les montants des différents produits importés, puis diviser cette somme par le nombre total de produits. \n",
      "\n",
      "En se basant sur les montants fournis dans le contexte, la somme totale des montants des produits importés en 2014 est de :\n",
      "\n",
      "956199283809 + 317445186814 + 265001872578 + 194894071158 + 166901969303 + 98389681548 + 96735387984 + 90573616601 + 86053487063 + 75783022037 = 2103946015315 FCFA\n",
      "\n",
      "Il y a un total de 10 produits importés en 2014.\n",
      "\n",
      "En divisant la somme totale par le nombre de produits, on obtient la moyenne des produits importés en 2014 :\n",
      "\n",
      "2103946015315 / 10 = 210394601531,5 FCFA\n",
      "\n",
      "Donc, la moyenne des produits importés en 2014 est de 210 394 601 531,5 FCFA.\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "❓ Pose ta question (ou 'exit') :  exit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 🔐 Chargement des variables d'environnement\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# ✅ Chemin robuste compatible Jupyter + Streamlit\n",
    "try:\n",
    "    BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "except NameError:\n",
    "    BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "\n",
    "CSV_PATH = os.path.join(BASE_DIR, \"data\", \"donnees_nettoyees.csv\")\n",
    "\n",
    "def charger_donnees():\n",
    "    return pd.read_csv(CSV_PATH)\n",
    "\n",
    "def extraire_contexte(question: str, df: pd.DataFrame) -> str:\n",
    "    question_lower = question.lower()\n",
    "    df_filtre = df.copy()\n",
    "\n",
    "    # 🔍 Filtrage flux\n",
    "    if \"export\" in question_lower:\n",
    "        df_filtre = df_filtre[df_filtre[\"Flux\"].str.contains(\"export\", case=False)]\n",
    "    elif \"import\" in question_lower:\n",
    "        df_filtre = df_filtre[df_filtre[\"Flux\"].str.contains(\"import\", case=False)]\n",
    "\n",
    "    # 🔍 Filtrage années multiples\n",
    "    annees = [int(mot) for mot in question_lower.split() if mot.isdigit() and 2000 <= int(mot) <= 2100]\n",
    "    if annees:\n",
    "        df_filtre = df_filtre[df_filtre[\"Année\"].isin(annees)]\n",
    "\n",
    "    # 🧮 Résumé\n",
    "    resume = (\n",
    "        df_filtre.groupby(\"Produit\")[\"Montant\"]\n",
    "        .sum()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(10)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    if resume.empty:\n",
    "        return \"Aucune donnée trouvée pour cette question.\"\n",
    "\n",
    "    texte = \"Produit\\tMontant total (FCFA)\\n\"\n",
    "    texte += \"\\n\".join([f\"{row['Produit']}\\t{row['Montant']:.0f}\" for _, row in resume.iterrows()])\n",
    "    return texte\n",
    "\n",
    "def generer_reponse_llm(question: str, contexte: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Tu es un assistant économique du Sénégal. Réponds à la question ci-dessous en te basant uniquement sur le CONTEXTE fourni.\n",
    "\n",
    "    CONTEXTE :\n",
    "    {contexte}\n",
    "\n",
    "    QUESTION :\n",
    "    {question}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Tu es un expert en commerce international du Sénégal.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"❌ Erreur lors de la génération : {e}\"\n",
    "\n",
    "def poser_question_llm(question: str) -> str:\n",
    "    df = charger_donnees()\n",
    "    contexte = extraire_contexte(question, df)\n",
    "    return generer_reponse_llm(question, contexte)\n",
    "\n",
    "# 🔁 Test local CLI\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🧪 Test du chatbot économique du Sénégal\\n\")\n",
    "    while True:\n",
    "        question = input(\"❓ Pose ta question (ou 'exit') : \")\n",
    "        if question.lower() in [\"exit\", \"quit\", \"q\"]:\n",
    "            break\n",
    "        reponse = poser_question_llm(question)\n",
    "        print(\"\\n🤖 Réponse :\\n\")\n",
    "        print(reponse)\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec864700-bc2f-45b1-8ae4-77f0f5a6a865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venvflux)",
   "language": "python",
   "name": "venvflux"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
