{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a939806f-ead7-4ea4-982a-fbfd3c1cb9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "735d96f6-a990-41ca-a375-d96fed880664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# üîê Chargement des variables d'environnement\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# ‚úÖ Chemin robuste pour compatibilit√© Jupyter + Streamlit\n",
    "try:\n",
    "    BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "except NameError:\n",
    "    BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "\n",
    "CSV_PATH = os.path.join(BASE_DIR, \"data\", \"donnees_nettoyees.csv\")\n",
    "\n",
    "def charger_donnees():\n",
    "    return pd.read_csv(CSV_PATH)\n",
    "\n",
    "def extraire_contexte(question: str, df: pd.DataFrame) -> str:\n",
    "    question_lower = question.lower()\n",
    "\n",
    "    # üîç Filtrage par flux\n",
    "    if \"export\" in question_lower:\n",
    "        df = df[df[\"Flux\"].str.contains(\"export\", case=False)]\n",
    "    elif \"import\" in question_lower:\n",
    "        df = df[df[\"Flux\"].str.contains(\"import\", case=False)]\n",
    "\n",
    "    # üîç Filtrage par ann√©e\n",
    "    for annee in df[\"Ann√©e\"].dropna().unique():\n",
    "        if str(int(annee)) in question_lower:\n",
    "            df = df[df[\"Ann√©e\"] == int(annee)]\n",
    "\n",
    "    # üßÆ R√©sum√© des montants par produit\n",
    "    resume = (\n",
    "        df.groupby(\"Produit\")[\"Montant\"]\n",
    "        .sum()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(10)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # üìú Formatage du contexte pour GPT\n",
    "    texte = \"Produit\\tMontant total (FCFA)\\n\"\n",
    "    texte += \"\\n\".join([f\"{row['Produit']}\\t{row['Montant']:.0f}\" for _, row in resume.iterrows()])\n",
    "    return texte\n",
    "\n",
    "def generer_reponse_llm(question: str, contexte: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Tu es un expert √©conomique du S√©n√©gal. R√©ponds √† la question suivante\n",
    "    en te basant uniquement sur le CONTEXTE fourni :\n",
    "\n",
    "    CONTEXTE :\n",
    "    {contexte}\n",
    "\n",
    "    QUESTION :\n",
    "    {question}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Tu es un analyste √©conomique du S√©n√©gal.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Erreur lors de la g√©n√©ration : {e}\"\n",
    "\n",
    "def poser_question_llm(question: str) -> str:\n",
    "    df = charger_donnees()\n",
    "    contexte = extraire_contexte(question, df)\n",
    "    return generer_reponse_llm(question, contexte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e130554a-1bc9-465c-a320-669951273e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Test du chatbot √©conomique du S√©n√©gal\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚ùì Pose ta question (ou 'exit') :  quels sont les produits les plus importes en 2014,2015 et 2016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ R√©ponse :\n",
      "\n",
      "Les produits les plus import√©s au S√©n√©gal en 2014, 2015 et 2016 sont les suivants, class√©s par ordre d√©croissant de montant total en FCFA :\n",
      "\n",
      "1. Combustibles min√©raux; huiles, cires min√©rales; mati√®res bitumineuses\n",
      "2. R√©acteurs nucl√©aires; chaudi√®res, machines, appareils, engins m√©caniques\n",
      "3. C√©r√©ales\n",
      "4. Voitures automobiles et autres v√©hicules terrestres; parties, accessoires\n",
      "5. Machines √©lectriques; appareils d'√©mission-r√©ception radio/TV\n",
      "\n",
      "Ces produits repr√©sentent les importations les plus importantes pour ces ann√©es donn√©es.\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚ùì Pose ta question (ou 'exit') :  la moyenne des produits importes en 2014 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ R√©ponse :\n",
      "\n",
      "Pour calculer la moyenne des produits import√©s en 2014, il faut d'abord additionner tous les montants des diff√©rents produits import√©s, puis diviser cette somme par le nombre total de produits. \n",
      "\n",
      "En se basant sur les montants fournis dans le contexte, la somme totale des montants des produits import√©s en 2014 est de :\n",
      "\n",
      "956199283809 + 317445186814 + 265001872578 + 194894071158 + 166901969303 + 98389681548 + 96735387984 + 90573616601 + 86053487063 + 75783022037 = 2103946015315 FCFA\n",
      "\n",
      "Il y a un total de 10 produits import√©s en 2014.\n",
      "\n",
      "En divisant la somme totale par le nombre de produits, on obtient la moyenne des produits import√©s en 2014 :\n",
      "\n",
      "2103946015315 / 10 = 210394601531,5 FCFA\n",
      "\n",
      "Donc, la moyenne des produits import√©s en 2014 est de 210 394 601 531,5 FCFA.\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚ùì Pose ta question (ou 'exit') :  exit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# üîê Chargement des variables d'environnement\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# ‚úÖ Chemin robuste compatible Jupyter + Streamlit\n",
    "try:\n",
    "    BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "except NameError:\n",
    "    BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "\n",
    "CSV_PATH = os.path.join(BASE_DIR, \"data\", \"donnees_nettoyees.csv\")\n",
    "\n",
    "def charger_donnees():\n",
    "    return pd.read_csv(CSV_PATH)\n",
    "\n",
    "def extraire_contexte(question: str, df: pd.DataFrame) -> str:\n",
    "    question_lower = question.lower()\n",
    "    df_filtre = df.copy()\n",
    "\n",
    "    # üîç Filtrage flux\n",
    "    if \"export\" in question_lower:\n",
    "        df_filtre = df_filtre[df_filtre[\"Flux\"].str.contains(\"export\", case=False)]\n",
    "    elif \"import\" in question_lower:\n",
    "        df_filtre = df_filtre[df_filtre[\"Flux\"].str.contains(\"import\", case=False)]\n",
    "\n",
    "    # üîç Filtrage ann√©es multiples\n",
    "    annees = [int(mot) for mot in question_lower.split() if mot.isdigit() and 2000 <= int(mot) <= 2100]\n",
    "    if annees:\n",
    "        df_filtre = df_filtre[df_filtre[\"Ann√©e\"].isin(annees)]\n",
    "\n",
    "    # üßÆ R√©sum√©\n",
    "    resume = (\n",
    "        df_filtre.groupby(\"Produit\")[\"Montant\"]\n",
    "        .sum()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(10)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    if resume.empty:\n",
    "        return \"Aucune donn√©e trouv√©e pour cette question.\"\n",
    "\n",
    "    texte = \"Produit\\tMontant total (FCFA)\\n\"\n",
    "    texte += \"\\n\".join([f\"{row['Produit']}\\t{row['Montant']:.0f}\" for _, row in resume.iterrows()])\n",
    "    return texte\n",
    "\n",
    "def generer_reponse_llm(question: str, contexte: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Tu es un assistant √©conomique du S√©n√©gal. R√©ponds √† la question ci-dessous en te basant uniquement sur le CONTEXTE fourni.\n",
    "\n",
    "    CONTEXTE :\n",
    "    {contexte}\n",
    "\n",
    "    QUESTION :\n",
    "    {question}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Tu es un expert en commerce international du S√©n√©gal.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Erreur lors de la g√©n√©ration : {e}\"\n",
    "\n",
    "def poser_question_llm(question: str) -> str:\n",
    "    df = charger_donnees()\n",
    "    contexte = extraire_contexte(question, df)\n",
    "    return generer_reponse_llm(question, contexte)\n",
    "\n",
    "# üîÅ Test local CLI\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üß™ Test du chatbot √©conomique du S√©n√©gal\\n\")\n",
    "    while True:\n",
    "        question = input(\"‚ùì Pose ta question (ou 'exit') : \")\n",
    "        if question.lower() in [\"exit\", \"quit\", \"q\"]:\n",
    "            break\n",
    "        reponse = poser_question_llm(question)\n",
    "        print(\"\\nü§ñ R√©ponse :\\n\")\n",
    "        print(reponse)\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec864700-bc2f-45b1-8ae4-77f0f5a6a865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venvflux)",
   "language": "python",
   "name": "venvflux"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
